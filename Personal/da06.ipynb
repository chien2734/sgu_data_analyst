{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvvPCyq6kYwEaF/syRcWSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chien2734/sgu_data_analyst/blob/main/Personal/da06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DA06 - BÀI TOÁN PHÂN LỚP"
      ],
      "metadata": {
        "id": "BOQYKcyknqjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 Giải thuật 1: Cây quyết định và rừng cây"
      ],
      "metadata": {
        "id": "WsBGHa0In4EI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 Ôn tập lý thuyết\n",
        "**Quy trình khai phá dữ liệu: CRISP-DM và SEMMA**\n",
        "\n",
        "CRISP-DM (Cross-Industry Standard Process for Data Mining)\n",
        "\n",
        "Đây là một quy trình chuẩn hóa, phổ biến và linh hoạt cho các dự án khai phá dữ liệu. Nó bao gồm 6 giai đoạn lặp đi lặp lại:\n",
        "1. **Business Understanding (Hiểu bài toán kinh doanh)**: Xác định mục tiêu của dự án từ góc độ kinh doanh. Đây là bước quan trọng nhất để đảm bảo dự án mang lại giá trị thực tế.\n",
        "2. **Data Understanding (Hiểu dữ liệu)**: Thu thập dữ liệu ban đầu và làm quen với nó. Bước này bao gồm việc khám phá dữ liệu để xác định các vấn đề về chất lượng.\n",
        "3. **Data Preparation (Chuẩn bị dữ liệu)**: Bao gồm tất cả các hoạt động để xây dựng tập dữ liệu cuối cùng từ dữ liệu thô. Các công việc thường làm là chọn bảng, bản ghi và thuộc tính, cũng như làm sạch và chuyển đổi dữ liệu.\n",
        "4. **Modeling (Mô hình hóa)**: Lựa chọn và áp dụng các kỹ thuật mô hình hóa khác nhau. Các tham số của mô hình được hiệu chỉnh để tối ưu hóa kết quả.\n",
        "5. **Evaluation (Đánh giá)**: Đánh giá mô hình đã xây dựng và xem xét các bước đã thực hiện để chắc chắn rằng mô hình đạt được mục tiêu kinh doanh.\n",
        "6. **Deployment (Triển khai)**: Đưa mô hình vào sử dụng thực tế. Giai đoạn này có thể đơn giản như tạo một báo cáo hoặc phức tạp như triển khai một quy trình khai phá dữ liệu lặp lại trong tổ chức.\n",
        "\n",
        "**SEMMA (Sample, Explore, Modify, Model, Assess)**\n",
        "\n",
        "Được phát triển bởi Viện SAS, SEMMA là một quy trình tập trung nhiều hơn vào các bước kỹ thuật của việc xây dựng mô hình.\n",
        "1. **Sample (Lấy mẫu)**: Chọn một tập dữ liệu đủ lớn nhưng vẫn có thể quản lý được từ một tập dữ liệu lớn hơn.\n",
        "2. **Explore (Khám phá)**: Trực quan hóa và khám phá dữ liệu để tìm kiếm các xu hướng và bất thường, từ đó có ý tưởng cho các bước tiếp theo.\n",
        "3. **Modify (Điều chỉnh)**: Tạo, chọn và chuyển đổi các biến để tập trung vào việc lựa chọn mô hình.\n",
        "4. **Model (Mô hình hóa)**: Áp dụng các thuật toán khai phá dữ liệu khác nhau để tìm ra mô hình dự đoán tốt nhất.\n",
        "5. **Assess (Đánh giá)**: Đánh giá độ tin cậy và hữu ích của các mô hình đã tìm thấy.\n",
        "\n",
        "**Cây Quyết Định (Decision Tree)**\n",
        "\n",
        "Cách hoạt động và các thành phần chínhCây quyết định là một mô hình học máy có giám sát, hoạt động giống như một lưu đồ. Nó đưa ra dự đoán bằng cách học các quy tắc quyết định đơn giản được suy ra từ các đặc trưng của dữ liệu.\n",
        "1. **Nút gốc (Root Node)**: Đây là nút trên cùng của cây, đại diện cho toàn bộ tập dữ liệu. Từ nút này, cây bắt đầu phân chia dữ liệu.\n",
        "2. **Nhánh (Branch)**: Mỗi nhánh đại diện cho một quy tắc quyết định (ví dụ: \"Tuổi > 30?\").\n",
        "3. **Nút lá (Leaf Node)**: Đây là các nút cuối cùng của cây, không phân chia nữa. Mỗi nút lá đại diện cho một kết quả dự đoán (một lớp trong bài toán phân loại hoặc một giá trị trong bài toán hồi quy).\n",
        "\n",
        "Cây đưa ra dự đoán bằng cách bắt đầu từ nút gốc và đi xuống cây theo các nhánh tương ứng với giá trị của các đặc trưng cho đến khi đến một nút lá. Kết quả dự đoán chính là nhãn của nút lá đó.\n",
        "\n",
        "**Các Tiêu Chí Phân Tách (Splitting Criteria)**\n",
        "\n",
        "Đây là các thước đo được sử dụng để quyết định đặc trưng nào và ngưỡng nào sẽ được dùng để phân chia một nút thành các nút con. Mục tiêu là tạo ra các nút con \"thuần khiết\" nhất có thể (chứa các mẫu thuộc cùng một lớp).\n",
        "* **Gini Index (Chỉ số Gini)**: Đo lường xác suất một phần tử được chọn ngẫu nhiên sẽ bị phân loại sai nếu nó được gán nhãn một cách ngẫu nhiên theo phân phối của các nhãn trong tập hợp con. Giá trị Gini càng thấp, độ \"thuần khiết\" của nút càng cao.$$ \\\\ Gini = 1 - \\sum\\_{i=1}^{C} (p\\_i)^2\n",
        "$$$$$$Trong đó $p_i$ là xác suất của lớp $i$.\n",
        "* **Entropy**: Là một thước đo sự hỗn loạn hoặc không chắc chắn trong một nút. Entropy bằng 0 khi nút hoàn toàn thuần khiết.$$ \\\\ Entropy = - \\sum\\_{i=1}^{C} p\\_i \\log\\_2(p\\_i)\n",
        "\n",
        "* **Information Gain (Lợi ích thông tin)**: Là sự giảm đi của Entropy sau khi một tập dữ liệu được phân chia dựa trên một đặc trưng. Cây quyết định luôn cố gắng chọn phép chia mang lại Information Gain cao nhất.\n",
        "$$ \\\\ Information Gain = Entropy(parent) - \\sum\\_{j=1}^{k} \\frac{N\\_j}{N} Entropy(child\\_j)\n",
        "$$\n",
        "\n",
        "**Sự khác biệt**: Cả ba đều nhằm mục đích đo lường độ thuần khiết, nhưng có công thức toán học khác nhau. Information Gain (dựa trên Entropy) có xu hướng ưu tiên các đặc trưng có nhiều giá trị, trong khi Gini Index cân bằng hơn. Trong thực tế, sự khác biệt về hiệu suất giữa chúng thường không lớn.\n",
        "\n",
        "**Rừng Ngẫu Nhiên (Random Forest)**\n",
        "\n",
        "**Random Forest là gì và khác gì cây quyết định?**\n",
        "**Random Forest** là một thuật toán học máy có giám sát thuộc loại \"ensemble learning\" (học tập hợp). Thay vì xây dựng một cây quyết định duy nhất, nó xây dựng nhiều cây quyết định trong quá trình huấn luyện.\n",
        "\n",
        "**Sự khác biệt**:\n",
        "1. **Số lượng cây**: Cây quyết định chỉ có một cây, trong khi Random Forest có một \"rừng\" gồm nhiều cây.\n",
        "2. **Cách xây dựng**:\n",
        "  * Mỗi cây trong Random Forest được huấn luyện trên một mẫu dữ liệu ngẫu nhiên có lặp lại (bootstrap sample) từ tập dữ liệu gốc.\n",
        "  * Tại mỗi nút, thay vì xem xét tất cả các đặc trưng, Random Forest chỉ chọn một tập con ngẫu nhiên của các đặc trưng để tìm phép chia tốt nhất.\n",
        "3. **Dự đoán**: Để phân loại, Random Forest lấy kết quả biểu quyết (majority vote) từ tất cả các cây. Đối với hồi quy, nó lấy giá trị trung bình.\n",
        "\n",
        "**Tại sao Random Forest thường hiệu quả hơn?**\n",
        "\n",
        "Random Forest thường có hiệu suất tốt hơn vì nó giảm thiểu được hiện tượng **overfitting** (học quá khớp). Một cây quyết định đơn lẻ có thể rất sâu và phức tạp, học thuộc lòng cả nhiễu trong dữ liệu huấn luyện. Bằng cách kết hợp dự đoán từ nhiều cây (mỗi cây chỉ nhìn thấy một phần dữ liệu và một phần đặc trưng), Random Forest tạo ra một mô hình tổng quát hóa tốt hơn.\n",
        "\n",
        "**Ưu điểm và Hạn chế**\n",
        "\n",
        "|       |Cây quyết định         |Random Forest                          |\n",
        "|-------|-----------------------|---------------------------------------|\n",
        "|Ưu điểm|- Dễ hiểu và diễn giải.|- Hiệu suất cao và thường rất chính xác|\n",
        "|       |- Yêu cầu ít tiền xử lý dữ liệu.|- Khả năng chống overfitting tốt.|\n",
        "|       |- Có thể xử lý cả dữ liệu số và dữ liệu hạng mục.|- Có thể xử lý tập dữ liệu lớn với nhiều đặc trưng.|\n",
        "|-------|-----------------------|---------------------------------------|\n",
        "|Hạn chế|- Dễ bị overfitting.   |- Là một mô hình \"hộp đen\", khó diễn giải hơn cây đơn lẻ.|\n",
        "|       |- Không ổn định, thay đổi nhỏ trong dữ liệu có thể tạo ra cây khác biệt lớn.| - Tốn nhiều tài nguyên tính toán và bộ nhớ hơn.|\n",
        "\n",
        "**Cây quyết định hoạt động kém hiệu quả** khi dữ liệu có nhiều đặc trưng phức tạp, liên quan đến nhau hoặc khi có nhiều nhiễu. Trong những trường hợp này, nó rất dễ bị overfitting.\n"
      ],
      "metadata": {
        "id": "W-Gat5fjoCIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2. Bài làm mẫu\n"
      ],
      "metadata": {
        "id": "0gLk-NTYuRPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bài toán 1: Xây dựng cây quyết định và rừng cây"
      ],
      "metadata": {
        "id": "vHdgdBgCuY7f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwgD42bVm2W1"
      },
      "outputs": [],
      "source": []
    }
  ]
}